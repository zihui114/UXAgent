"""
UX Analyzer - åˆ†ææ¸¬è©¦çµæœä¸¦ç”¢ç”Ÿé‡å° persona çš„ UX æ”¹å–„å»ºè­°

ä½¿ç”¨æ–¹å¼:
    python src/ux_analyzer.py --run-dir runs/2026-01-01_16-26-27_f19e --persona persona_routine_buyer_nianjia.txt
"""

import json
import re
import argparse
from pathlib import Path
from typing import Dict, List, Any
from datetime import datetime


class PersonaProfile:
    """è§£æä¸¦å„²å­˜ persona ç‰¹å¾µ"""

    def __init__(self, persona_file: str):
        self.raw_text = Path(persona_file).read_text(encoding='utf-8')
        self.name = self._extract_name()
        self.age = self._extract_field('Age')
        self.persona_type = self._extract_persona_type()
        self.risk_perception = self._extract_level('é¢¨éšªæ„ŸçŸ¥|Risk Perception')
        self.self_efficacy = self._extract_level('è‡ªæˆ‘æ•ˆèƒ½|Self-Efficacy')
        self.working_memory = self._extract_level('å·¥ä½œè¨˜æ†¶å®¹å¿åº¦|Working Memory Tolerance|Working Memory')
        self.strategy = self._extract_strategy()

    def _extract_name(self) -> str:
        # Try to find name like "Mrs. Wang" or "Mr. Chen"
        match = re.search(r'(Mrs?|Ms)\.\s+([A-Z][a-z]+)', self.raw_text)
        if match:
            return f"{match.group(1)}. {match.group(2)}"

        # Try Chinese name format
        match = re.search(r'(ç‹|é™³|æ|å¼µ|æ—|å³|é»ƒ|å‘¨|å¾|å­«|é¦¬|æœ±|èƒ¡|éƒ­|ä½•|é«˜|ç¾…|é„­|æ¢|è¬|å®‹|å”|è¨±|é„§|é¦®|éŸ“|æ›¹|æ›¾|å½­|è•­|è”¡|æ½˜|ç”°|è‘£|è¢|æ–¼|ä½™|è‘‰|è”£|æœ|è˜‡|é­|ç¨‹|å‘‚|ä¸|æ²ˆ|ä»»|å§š|ç›§|å‚…|é¾|å§œ|å´”|è­š|å»–|èŒƒ|æ±ª|é™¸|é‡‘|çŸ³|æˆ´|è³ˆ|éŸ‹|å¤|é‚±|æ–¹|ä¾¯|é„’|ç†Š|å­Ÿ|ç§¦|ç™½|æ±Ÿ|é–»|è–›|å°¹|æ®µ|é›·|é»|å²|é¾|é™¶|è³€|é¡§|æ¯›|éƒ|é¾”|é‚µ|è¬|éŒ¢|åš´|è¦ƒ|æ­¦|æˆ´|è«|å­”|å‘|å¸¸)(å…ˆç”Ÿ|å¥³å£«|å¤ªå¤ª)', self.raw_text)
        if match:
            return f"{match.group(1)}{match.group(2)}"

        # Fallback to "Unknown"
        return "Unknown"

    def _extract_field(self, pattern: str) -> str:
        match = re.search(f'({pattern})[ï¼š:]\\s*([^\n]+)', self.raw_text)
        return match.group(2).strip() if match else "Unknown"

    def _extract_persona_type(self) -> str:
        if 'è¬¹æ…é©—è­‰å‹' in self.raw_text or 'Cautious Verifier' in self.raw_text:
            return 'cautious_verifier'
        elif 'æ•ˆç‡å°å‘å‹' in self.raw_text or 'Routine Buyer' in self.raw_text:
            return 'efficiency_oriented'
        return 'unknown'

    def _extract_level(self, pattern: str) -> str:
        match = re.search(f'({pattern})[ï¼š:]\\s*([^\n]+)', self.raw_text, re.IGNORECASE)
        if match:
            level_text = match.group(2).upper()
            if 'HIGH' in level_text or 'é«˜' in level_text:
                return 'HIGH'
            elif 'LOW' in level_text or 'ä½' in level_text:
                return 'LOW'
            elif 'MEDIUM' in level_text or 'ä¸­' in level_text:
                return 'MEDIUM'
        return 'UNKNOWN'

    def _extract_strategy(self) -> str:
        if 'VERIFICATION-ORIENTED' in self.raw_text or 'é©—è­‰å°å‘' in self.raw_text:
            return 'verification'
        elif 'GOAL-ORIENTED' in self.raw_text or 'ç›®æ¨™å°å‘' in self.raw_text:
            return 'goal_oriented'
        return 'unknown'


class BehaviorAnalyzer:
    """åˆ†ææ¸¬è©¦ä¸­çš„è¡Œç‚ºæ¨¡å¼"""

    def __init__(self, memory_trace: List[Dict]):
        self.memory_trace = memory_trace
        self.actions = [e for e in memory_trace if e.get('kind') == 'action']
        self.observations = [e for e in memory_trace if e.get('kind') == 'observation']
        self.reflections = [e for e in memory_trace if e.get('kind') == 'reflection']

    def detect_repeated_actions(self) -> List[Dict[str, Any]]:
        """æª¢æ¸¬é‡è¤‡å‹•ä½œï¼ˆå¯èƒ½è¡¨ç¤ºç¼ºä¹å›é¥‹ï¼‰"""
        repeated = []
        action_sequence = []

        for action in self.actions:
            content = action.get('content', '')
            action_sequence.append(content)

        # å°‹æ‰¾é€£çºŒé‡è¤‡çš„å‹•ä½œ
        i = 0
        while i < len(action_sequence) - 1:
            current = action_sequence[i]
            count = 1
            j = i + 1

            # æª¢æŸ¥æ˜¯å¦ç‚ºç›¸åŒæˆ–ç›¸ä¼¼çš„å‹•ä½œ
            while j < len(action_sequence):
                if self._is_similar_action(current, action_sequence[j]):
                    count += 1
                    j += 1
                else:
                    break

            if count >= 2:  # é‡è¤‡ 2 æ¬¡ä»¥ä¸Š
                repeated.append({
                    'action': current[:100],
                    'count': count,
                    'timestamp_start': self.actions[i].get('timestamp', 0),
                    'type': self._classify_action(current)
                })
                i = j
            else:
                i += 1

        return repeated

    def _is_similar_action(self, action1: str, action2: str) -> bool:
        """åˆ¤æ–·å…©å€‹å‹•ä½œæ˜¯å¦ç›¸ä¼¼"""
        # æå–é—œéµè©
        keywords1 = set(re.findall(r'[\u4e00-\u9fff]+', action1))
        keywords2 = set(re.findall(r'[\u4e00-\u9fff]+', action2))

        if keywords1 and keywords2:
            overlap = len(keywords1 & keywords2) / len(keywords1 | keywords2)
            return overlap > 0.5

        return action1 == action2

    def _classify_action(self, action: str) -> str:
        """åˆ†é¡å‹•ä½œé¡å‹"""
        if 'åŠ å…¥è³¼ç‰©è»Š' in action or 'Add to Cart' in action:
            return 'add_to_cart'
        elif 'æœå°‹' in action or 'search' in action.lower():
            return 'search'
        elif 'é»æ“Š' in action or 'click' in action.lower():
            return 'navigation'
        elif 'æ»¾å‹•' in action or 'scroll' in action.lower():
            return 'scroll'
        return 'other'

    def detect_confusion_signals(self) -> List[Dict[str, Any]]:
        """å¾ reflections ä¸­æª¢æ¸¬å›°æƒ‘è¨Šè™Ÿ"""
        confusion_keywords = [
            'ä¸ç¢ºå®š', 'æ‰¾ä¸åˆ°', 'æ²’æœ‰çœ‹åˆ°', 'ä¸æ¸…æ¥š', 'å›°æƒ‘',
            'unsure', 'cannot find', 'not clear', 'confused',
            'é‡è©¦', 'retry', 'å†è©¦', 'å¤±æ•—', 'failed'
        ]

        signals = []
        for reflection in self.reflections:
            content = reflection.get('content', '')
            for keyword in confusion_keywords:
                if keyword in content.lower():
                    signals.append({
                        'timestamp': reflection.get('timestamp', 0),
                        'content': content[:200],
                        'keyword': keyword
                    })
                    break

        return signals

    def calculate_task_efficiency(self) -> Dict[str, Any]:
        """è¨ˆç®—ä»»å‹™æ•ˆç‡æŒ‡æ¨™"""
        total_actions = len(self.actions)
        total_time = 0

        if self.actions:
            start_time = self.actions[0].get('timestamp', 0)
            end_time = self.actions[-1].get('timestamp', 0)
            total_time = end_time - start_time

        return {
            'total_actions': total_actions,
            'total_time_ms': total_time,
            'actions_per_second': total_actions / (total_time / 1000) if total_time > 0 else 0
        }

    def detect_navigation_issues(self) -> List[Dict[str, Any]]:
        """æª¢æ¸¬å°èˆªå•é¡Œï¼ˆéå¤šæ»¾å‹•ã€è¿”å›ç­‰ï¼‰"""
        issues = []
        scroll_count = 0
        back_count = 0

        for action in self.actions:
            content = action.get('content', '').lower()
            if 'scroll' in content or 'æ»¾å‹•' in content:
                scroll_count += 1
            if 'back' in content or 'è¿”å›' in content or 'ä¸Šä¸€é ' in content:
                back_count += 1

        if scroll_count > 10:
            issues.append({
                'type': 'excessive_scrolling',
                'count': scroll_count,
                'severity': 'medium' if scroll_count < 20 else 'high'
            })

        if back_count > 3:
            issues.append({
                'type': 'frequent_backtracking',
                'count': back_count,
                'severity': 'high'
            })

        return issues


class UXRecommendationGenerator:
    """æ ¹æ“š persona ç‰¹å¾µå’Œè¡Œç‚ºæ¨¡å¼ç”¢ç”Ÿ UX å»ºè­°"""

    def __init__(self, persona: PersonaProfile, behavior: BehaviorAnalyzer):
        self.persona = persona
        self.behavior = behavior

    def generate_recommendations(self) -> Dict[str, Any]:
        """ç”¢ç”Ÿå®Œæ•´çš„ UX æ”¹å–„å»ºè­°å ±å‘Š"""
        recommendations = {
            'persona_info': {
                'name': self.persona.name,
                'type': self.persona.persona_type,
                'key_traits': {
                    'risk_perception': self.persona.risk_perception,
                    'self_efficacy': self.persona.self_efficacy,
                    'working_memory': self.persona.working_memory,
                    'strategy': self.persona.strategy
                }
            },
            'detected_issues': [],
            'recommendations': [],
            'priority_actions': []
        }

        # åˆ†æé‡è¤‡å‹•ä½œ
        repeated_actions = self.behavior.detect_repeated_actions()
        if repeated_actions:
            for repeat in repeated_actions:
                issue = self._analyze_repeated_action(repeat)
                if issue:
                    recommendations['detected_issues'].append(issue)
                    recommendations['recommendations'].extend(
                        self._generate_feedback_recommendations(repeat, issue)
                    )

        # åˆ†æå›°æƒ‘è¨Šè™Ÿ
        confusion_signals = self.behavior.detect_confusion_signals()
        if confusion_signals:
            issue = {
                'type': 'user_confusion',
                'severity': 'high',
                'count': len(confusion_signals),
                'examples': [s['content'] for s in confusion_signals[:3]]
            }
            recommendations['detected_issues'].append(issue)
            recommendations['recommendations'].extend(
                self._generate_clarity_recommendations(confusion_signals)
            )

        # åˆ†æå°èˆªå•é¡Œ
        nav_issues = self.behavior.detect_navigation_issues()
        if nav_issues:
            recommendations['detected_issues'].extend(nav_issues)
            recommendations['recommendations'].extend(
                self._generate_navigation_recommendations(nav_issues)
            )

        # åˆ†æä»»å‹™æ•ˆç‡
        efficiency = self.behavior.calculate_task_efficiency()
        recommendations['task_metrics'] = efficiency

        # æ ¹æ“š persona é¡å‹èª¿æ•´å»ºè­°å„ªå…ˆç´š
        recommendations['priority_actions'] = self._prioritize_by_persona(
            recommendations['recommendations']
        )

        return recommendations

    def _analyze_repeated_action(self, repeat: Dict) -> Dict[str, Any]:
        """åˆ†æé‡è¤‡å‹•ä½œçš„åŸå› """
        action_type = repeat['type']
        count = repeat['count']

        if action_type == 'add_to_cart' and count >= 2:
            return {
                'type': 'insufficient_feedback',
                'severity': 'high',
                'action': repeat['action'],
                'repeat_count': count,
                'description': f'ä½¿ç”¨è€…é‡è¤‡é»æ“Šã€ŒåŠ å…¥è³¼ç‰©è»Šã€{count}æ¬¡ï¼Œè¡¨ç¤ºç¼ºä¹æ˜ç¢ºçš„æˆåŠŸå›é¥‹'
            }

        return None

    def _generate_feedback_recommendations(self, repeat: Dict, issue: Dict) -> List[Dict]:
        """é‡å°å›é¥‹ä¸è¶³ç”¢ç”Ÿå»ºè­°"""
        recs = []

        if self.persona.persona_type == 'efficiency_oriented':
            # æ•ˆç‡å‹ä½¿ç”¨è€…ï¼šéœ€è¦å³æ™‚ã€æ˜ç¢ºçš„å›é¥‹
            recs.append({
                'category': 'Visual Feedback',
                'priority': 'HIGH',
                'title': 'å¢å¼·å³æ™‚è¦–è¦ºå›é¥‹',
                'description': f'{self.persona.name} æ˜¯æ•ˆç‡å°å‘å‹ä½¿ç”¨è€…ï¼ŒæœŸæœ›å¿«é€Ÿå®Œæˆä»»å‹™ã€‚é‡è¤‡é»æ“Š {repeat["count"]} æ¬¡è¡¨ç¤ºå›é¥‹ä¸å¤ æ˜é¡¯ã€‚',
                'recommendations': [
                    'åœ¨æŒ‰éˆ•é»æ“Šå¾Œç«‹å³é¡¯ç¤ºå¤§å‹ã€æ˜é¡¯çš„æˆåŠŸæç¤ºï¼ˆè‡³å°‘åœç•™ 2-3 ç§’ï¼‰',
                    'è³¼ç‰©è»Šåœ–ç¤ºåŠ å…¥è·³å‹•å‹•ç•« + æ•¸é‡å¾½ç« æ”¾å¤§æ•ˆæœ',
                    'æŒ‰éˆ•ç‹€æ…‹è®ŠåŒ–ï¼šé»æ“Šå¾ŒçŸ­æš«é¡¯ç¤ºã€Œâœ“ å·²åŠ å…¥ã€æ–‡å­—ä¸¦è®Šè‰²',
                    'è€ƒæ…®åŠ å…¥è²éŸ³æç¤ºï¼ˆå¯é¸ï¼‰'
                ],
                'persona_specific': f'æ•ˆç‡å‹ä½¿ç”¨è€…ï¼ˆè‡ªæˆ‘æ•ˆèƒ½: {self.persona.self_efficacy}ï¼‰éœ€è¦ç¢ºå®šæ€§ï¼Œé¿å…é‡è¤‡æ“ä½œæµªè²»æ™‚é–“'
            })

        elif self.persona.persona_type == 'cautious_verifier':
            # è¬¹æ…å‹ä½¿ç”¨è€…ï¼šéœ€è¦è©³ç´°ã€å¯é©—è­‰çš„å›é¥‹
            recs.append({
                'category': 'Detailed Feedback',
                'priority': 'HIGH',
                'title': 'æä¾›è©³ç´°ä¸”å¯é©—è­‰çš„å›é¥‹è¨Šæ¯',
                'description': f'{self.persona.name} æ˜¯è¬¹æ…é©—è­‰å‹ä½¿ç”¨è€…ï¼Œéœ€è¦ç¢ºèªæ“ä½œçµæœã€‚',
                'recommendations': [
                    'é¡¯ç¤ºè©³ç´°çš„æˆåŠŸè¨Šæ¯ï¼šã€Œå·²æˆåŠŸåŠ å…¥ [å•†å“åç¨±] x1 åˆ°è³¼ç‰©è»Šã€',
                    'æä¾›ã€ŒæŸ¥çœ‹è³¼ç‰©è»Šã€æŒ‰éˆ•ï¼Œè®“ä½¿ç”¨è€…å¯ä»¥ç«‹å³é©—è­‰',
                    'åœ¨è³¼ç‰©è»Šå€åŸŸé¡¯ç¤ºå®Œæ•´çš„å•†å“ç¸®åœ–å’Œåç¨±',
                    'ä¿æŒè¨Šæ¯é¡¯ç¤ºæ›´é•·æ™‚é–“ï¼ˆ5-7 ç§’ï¼‰ï¼Œæˆ–æä¾›æ‰‹å‹•é—œé–‰é¸é …'
                ],
                'persona_specific': f'è¬¹æ…å‹ä½¿ç”¨è€…ï¼ˆé¢¨éšªæ„ŸçŸ¥: {self.persona.risk_perception}ï¼‰éœ€è¦å®Œæ•´è³‡è¨Šä¾†é™ä½ä¸ç¢ºå®šæ€§'
            })

        return recs

    def _generate_clarity_recommendations(self, signals: List[Dict]) -> List[Dict]:
        """é‡å°å›°æƒ‘è¨Šè™Ÿç”¢ç”Ÿå»ºè­°"""
        recs = []

        if self.persona.working_memory == 'LOW':
            recs.append({
                'category': 'Information Architecture',
                'priority': 'HIGH',
                'title': 'ç°¡åŒ–è³‡è¨Šæ¶æ§‹ï¼Œé™ä½èªçŸ¥è² è·',
                'description': f'{self.persona.name} å·¥ä½œè¨˜æ†¶å®¹å¿åº¦è¼ƒä½ï¼Œè¤‡é›œçš„ä»‹é¢æœƒé€ æˆå›°æƒ‘ã€‚',
                'recommendations': [
                    'æ¸›å°‘æ¯å€‹é é¢çš„è³‡è¨Šé‡ï¼Œæ¡ç”¨åˆ†æ­¥é©Ÿå¼•å°',
                    'ä½¿ç”¨æ˜ç¢ºçš„è¦–è¦ºå±¤ç´šï¼ˆæ¨™é¡Œã€å‰¯æ¨™é¡Œã€å…§å®¹ï¼‰',
                    'é‡è¦æ“ä½œæŒ‰éˆ•ä½¿ç”¨é«˜å°æ¯”è‰²ï¼Œé¿å…è¢«å¿½ç•¥',
                    'åŠ å…¥é€²åº¦æŒ‡ç¤ºå™¨ï¼ˆå¦‚ï¼šæ­¥é©Ÿ 1/3ï¼‰'
                ],
                'persona_specific': f'ä½å·¥ä½œè¨˜æ†¶ä½¿ç”¨è€…éœ€è¦æ¸…æ™°çš„è·¯å¾‘ï¼Œé¿å…ä¸€æ¬¡è™•ç†å¤ªå¤šè³‡è¨Š'
            })

        return recs

    def _generate_navigation_recommendations(self, issues: List[Dict]) -> List[Dict]:
        """é‡å°å°èˆªå•é¡Œç”¢ç”Ÿå»ºè­°"""
        recs = []

        for issue in issues:
            if issue['type'] == 'excessive_scrolling':
                recs.append({
                    'category': 'Layout Optimization',
                    'priority': 'MEDIUM',
                    'title': 'å„ªåŒ–é é¢ä½ˆå±€ï¼Œæ¸›å°‘æ»¾å‹•éœ€æ±‚',
                    'description': f'ä½¿ç”¨è€…éœ€è¦æ»¾å‹• {issue["count"]} æ¬¡æ‰èƒ½æ‰¾åˆ°ç›®æ¨™ï¼Œé¡¯ç¤ºé‡è¦è³‡è¨Šå¯èƒ½è¢«éš±è—ã€‚',
                    'recommendations': [
                        'å°‡é—œéµæ“ä½œæŒ‰éˆ•ï¼ˆåŠ å…¥è³¼ç‰©è»Šã€è³¼è²·ï¼‰ç½®æ–¼é¦–å±å¯è¦‹ç¯„åœ',
                        'ä½¿ç”¨ã€Œç½®é ‚ã€æˆ–ã€Œæµ®å‹•ã€æŒ‰éˆ•è¨­è¨ˆ',
                        'å„ªåŒ–å•†å“é é¢çµæ§‹ï¼Œå°‡åƒ¹æ ¼å’Œè³¼è²·æŒ‰éˆ•æ”¾åœ¨æ›´é¡¯çœ¼ä½ç½®',
                        'è€ƒæ…®ä½¿ç”¨ã€Œå›åˆ°é ‚éƒ¨ã€å¿«é€Ÿå°èˆªæŒ‰éˆ•'
                    ],
                    'persona_specific': f'{self.persona.persona_type} é¡å‹ä½¿ç”¨è€…æœŸæœ›å¿«é€Ÿæ‰¾åˆ°ç›®æ¨™'
                })

            elif issue['type'] == 'frequent_backtracking':
                recs.append({
                    'category': 'Navigation Flow',
                    'priority': 'HIGH',
                    'title': 'æ”¹å–„å°èˆªæµç¨‹ï¼Œæ¸›å°‘è¿”å›æ“ä½œ',
                    'description': f'ä½¿ç”¨è€…é »ç¹è¿”å›ä¸Šä¸€é ï¼ˆ{issue["count"]} æ¬¡ï¼‰ï¼Œé¡¯ç¤ºæµç¨‹ä¸é †æš¢ã€‚',
                    'recommendations': [
                        'æª¢è¦–è³‡è¨Šæ¶æ§‹ï¼Œç¢ºä¿ä½¿ç”¨è€…èƒ½åœ¨ç•¶å‰é é¢å®Œæˆä»»å‹™',
                        'åŠ å…¥ã€ŒéºµåŒ…å±‘ã€å°èˆªï¼Œæ¸…æ¥šé¡¯ç¤ºç•¶å‰ä½ç½®',
                        'æä¾›ç›¸é—œæ¨è–¦æˆ–é€£çµï¼Œæ¸›å°‘è¿”å›éœ€æ±‚',
                        'ç¢ºä¿æ‰€æœ‰å¿…è¦è³‡è¨Šéƒ½åœ¨åŒä¸€é é¢å¯è¦‹'
                    ],
                    'persona_specific': 'é »ç¹è¿”å›è¡¨ç¤ºä½¿ç”¨è€…è¿·å¤±æˆ–è³‡è¨Šä¸å®Œæ•´'
                })

        return recs

    def _prioritize_by_persona(self, recommendations: List[Dict]) -> List[str]:
        """æ ¹æ“š persona ç‰¹å¾µæ’åºå„ªå…ˆè¡Œå‹•"""
        priorities = []

        high_priority_recs = [r for r in recommendations if r.get('priority') == 'HIGH']

        if self.persona.persona_type == 'efficiency_oriented':
            priorities.append('ğŸ¯ æ•ˆç‡å‹ä½¿ç”¨è€…æœ€éœ€è¦ï¼šç«‹å³ã€æ˜ç¢ºçš„æ“ä½œå›é¥‹')
            for rec in high_priority_recs:
                if 'feedback' in rec.get('category', '').lower():
                    priorities.append(f"   â†’ {rec['title']}")

        elif self.persona.persona_type == 'cautious_verifier':
            priorities.append('ğŸ¯ è¬¹æ…å‹ä½¿ç”¨è€…æœ€éœ€è¦ï¼šè©³ç´°ã€å¯é©—è­‰çš„è³‡è¨Š')
            for rec in high_priority_recs:
                if 'detail' in rec.get('category', '').lower() or 'clarity' in rec.get('category', '').lower():
                    priorities.append(f"   â†’ {rec['title']}")

        return priorities


def generate_report(recommendations: Dict, output_file: str):
    """ç”¢ç”Ÿæ˜“è®€çš„ Markdown å ±å‘Š"""
    persona = recommendations['persona_info']

    report = f"""# UX åˆ†æå ±å‘Š

## Persona è³‡è¨Š
- **å§“å**: {persona['name']}
- **é¡å‹**: {persona['type']}
- **é—œéµç‰¹å¾µ**:
  - é¢¨éšªæ„ŸçŸ¥: {persona['key_traits']['risk_perception']}
  - è‡ªæˆ‘æ•ˆèƒ½: {persona['key_traits']['self_efficacy']}
  - å·¥ä½œè¨˜æ†¶: {persona['key_traits']['working_memory']}
  - ä»»å‹™ç­–ç•¥: {persona['key_traits']['strategy']}

## æ¸¬è©¦æŒ‡æ¨™
- ç¸½æ“ä½œæ¬¡æ•¸: {recommendations['task_metrics']['total_actions']}
- ç¸½è€—æ™‚: {recommendations['task_metrics']['total_time_ms'] / 1000:.2f} ç§’
- æ“ä½œé »ç‡: {recommendations['task_metrics']['actions_per_second']:.2f} æ¬¡/ç§’

## ç™¼ç¾çš„ UX å•é¡Œ
"""

    for i, issue in enumerate(recommendations['detected_issues'], 1):
        report += f"\n### å•é¡Œ {i}: {issue.get('type', 'Unknown')}\n"
        report += f"- **åš´é‡ç¨‹åº¦**: {issue.get('severity', 'Unknown').upper()}\n"
        report += f"- **èªªæ˜**: {issue.get('description', 'N/A')}\n"
        if 'repeat_count' in issue:
            report += f"- **é‡è¤‡æ¬¡æ•¸**: {issue['repeat_count']}\n"

    report += "\n## é‡å°æ­¤ Persona çš„æ”¹å–„å»ºè­°\n"

    for i, rec in enumerate(recommendations['recommendations'], 1):
        report += f"\n### å»ºè­° {i}: {rec['title']}\n"
        report += f"- **é¡åˆ¥**: {rec['category']}\n"
        report += f"- **å„ªå…ˆç´š**: {rec['priority']}\n"
        report += f"- **æƒ…å¢ƒ**: {rec['description']}\n"
        report += f"- **Persona ç‰¹å®šè€ƒé‡**: {rec.get('persona_specific', 'N/A')}\n"
        report += "\n**å…·é«”å»ºè­°**:\n"
        for suggestion in rec.get('recommendations', []):
            report += f"  - {suggestion}\n"

    report += "\n## å„ªå…ˆè¡Œå‹•é …ç›®\n"
    for action in recommendations['priority_actions']:
        report += f"{action}\n"

    report += f"\n---\n*å ±å‘Šç”¢ç”Ÿæ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*\n"

    # å¯«å…¥æª”æ¡ˆ
    Path(output_file).write_text(report, encoding='utf-8')
    print(f"\nâœ… UX åˆ†æå ±å‘Šå·²ç”¢ç”Ÿ: {output_file}")

    return report


def main():
    parser = argparse.ArgumentParser(description='åˆ†ææ¸¬è©¦çµæœä¸¦ç”¢ç”Ÿ UX å»ºè­°')
    parser.add_argument('--run-dir', required=True, help='æ¸¬è©¦çµæœç›®éŒ„ (ä¾‹å¦‚: runs/2026-01-01_16-26-27_f19e)')
    parser.add_argument('--persona', required=True, help='Persona æª”æ¡ˆè·¯å¾‘')
    parser.add_argument('--output', help='è¼¸å‡ºå ±å‘Šæª”æ¡ˆè·¯å¾‘ (é è¨­: run-dir/ux_analysis.md)')

    args = parser.parse_args()

    run_dir = Path(args.run_dir)
    memory_trace_file = run_dir / 'memory_trace.json'

    if not memory_trace_file.exists():
        print(f"âŒ æ‰¾ä¸åˆ° memory_trace.json: {memory_trace_file}")
        return

    if not Path(args.persona).exists():
        print(f"âŒ æ‰¾ä¸åˆ° persona æª”æ¡ˆ: {args.persona}")
        return

    print(f"ğŸ“Š é–‹å§‹åˆ†ææ¸¬è©¦çµæœ...")
    print(f"   æ¸¬è©¦ç›®éŒ„: {run_dir}")
    print(f"   Persona: {args.persona}")

    # è®€å–è³‡æ–™
    with open(memory_trace_file, 'r', encoding='utf-8') as f:
        memory_trace = json.load(f)

    # å»ºç«‹åˆ†æå™¨
    persona = PersonaProfile(args.persona)
    print(f"\nğŸ‘¤ Persona: {persona.name} ({persona.persona_type})")

    behavior = BehaviorAnalyzer(memory_trace)
    print(f"ğŸ“ˆ åˆ†æ {len(behavior.actions)} å€‹å‹•ä½œ, {len(behavior.reflections)} å€‹åæ€")

    # ç”¢ç”Ÿå»ºè­°
    generator = UXRecommendationGenerator(persona, behavior)
    recommendations = generator.generate_recommendations()

    # ç”¢ç”Ÿå ±å‘Š
    output_file = args.output or str(run_dir / 'ux_analysis.md')
    report = generate_report(recommendations, output_file)

    # åŒæ™‚å„²å­˜ JSON æ ¼å¼
    json_output = str(run_dir / 'ux_analysis.json')
    with open(json_output, 'w', encoding='utf-8') as f:
        json.dump(recommendations, f, ensure_ascii=False, indent=2)
    print(f"âœ… JSON è³‡æ–™å·²å„²å­˜: {json_output}")

    # åœ¨çµ‚ç«¯é¡¯ç¤ºæ‘˜è¦
    print("\n" + "="*60)
    print("UX åˆ†ææ‘˜è¦")
    print("="*60)
    print(f"\nç™¼ç¾ {len(recommendations['detected_issues'])} å€‹ UX å•é¡Œ")
    print(f"ç”¢ç”Ÿ {len(recommendations['recommendations'])} é …æ”¹å–„å»ºè­°\n")

    if recommendations['priority_actions']:
        print("ğŸ¯ å„ªå…ˆè¡Œå‹•é …ç›®:")
        for action in recommendations['priority_actions']:
            print(f"  {action}")

    print(f"\nğŸ“„ å®Œæ•´å ±å‘Šè«‹è¦‹: {output_file}")


if __name__ == '__main__':
    main()
